# Быстрый старт после рефакторинга

## Что изменилось

Проект теперь использует **Stable-Baselines3** вместо самописной реализации. Это означает:

- ✅ Меньше кода для поддержки
- ✅ Более надежные алгоритмы
- ✅ Встроенная поддержка TensorBoard
- ✅ Легко переключаться между алгоритмами

## Установка

```bash
poetry install
```

Это установит `stable-baselines3` и `tensorboard`.

## Запуск обучения

### Новый способ (рекомендуется):

```bash
python train_sb3.py
```

### Старый способ (для сравнения):

```bash
python train_single_agent.py
```

## Основные отличия

### Старый код:
- Самописный `DDPGAgent` с ручным управлением replay buffer
- Ручной training loop
- Самописные Actor/Critic сети
- Ручное управление target networks

### Новый код:
- Использует `TD3` или `DDPG` из SB3
- Автоматический training loop через `model.learn()`
- Стандартные MLP политики (настраиваемые)
- Автоматическое управление target networks

## Конфигурация

Все гиперпараметры остались в `config/train_config.py` и используются в `train_sb3.py`.

## Мониторинг

После запуска обучения можно смотреть прогресс в TensorBoard:

```bash
tensorboard --logdir ./tensorboard_logs/
```

## Что осталось кастомным

1. **Окружение** (`env/drone_env.py`) - логика дрона и награды
2. **Генераторы** (`utils/generation.py`) - создание сценариев
3. **Визуализация** (`utils/save.py`) - графики эпизодов
4. **DB логирование** (`utils/db.py`) - сохранение в DuckDB

## Следующие шаги

1. Протестировать `train_sb3.py`
2. Сравнить результаты со старым кодом
3. Улучшить callbacks для полного логирования в БД
4. После проверки можно удалить старые файлы (см. REFACTORING.md)
