# –†–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–µ–∫—Ç–∞: –ø–µ—Ä–µ—Ö–æ–¥ –Ω–∞ Stable-Baselines3

## –û–±–∑–æ—Ä –∏–∑–º–µ–Ω–µ–Ω–∏–π

–ü—Ä–æ–µ–∫—Ç –±—ã–ª —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–µ–Ω –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ **Stable-Baselines3** –≤–º–µ—Å—Ç–æ —Å–∞–º–æ–ø–∏—Å–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ DDPG/MADDPG. –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞—Ç—å ~90% –∫–æ–¥–∞, —Å–≤—è–∑–∞–Ω–Ω–æ–≥–æ —Å –æ–±—É—á–µ–Ω–∏–µ–º RL, –∏ —Å–æ—Å—Ä–µ–¥–æ—Ç–æ—á–∏—Ç—å—Å—è –Ω–∞ –∫–∞—Å—Ç–æ–º–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞—Ö –ø—Ä–æ–µ–∫—Ç–∞.

## –ß—Ç–æ –±—ã–ª–æ –∑–∞–º–µ–Ω–µ–Ω–æ –±–∏–±–ª–∏–æ—Ç–µ–∫–∞–º–∏

### ‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–æ —á–µ—Ä–µ–∑ SB3:

1. **–ê–ª–≥–æ—Ä–∏—Ç–º—ã –æ–±—É—á–µ–Ω–∏—è** (`agents/ddpg_agent.py`, `agents/maddpg_agent.py`)
   - –ó–∞–º–µ–Ω–µ–Ω–æ –Ω–∞: `stable_baselines3.TD3` –∏–ª–∏ `stable_baselines3.DDPG`
   - –í–∫–ª—é—á–∞–µ—Ç: target networks, soft updates, –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä—ã

2. **Replay Buffer** (`utils/per_replay_buffer.py`)
   - –ó–∞–º–µ–Ω–µ–Ω–æ –Ω–∞: –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π replay buffer –≤ SB3 (—Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π PER —á–µ—Ä–µ–∑ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã)
   - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞–º–∏ –∏ sampling

3. **–ù–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏** (`networks/actor.py`, `networks/critic.py`)
   - –ó–∞–º–µ–Ω–µ–Ω–æ –Ω–∞: —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ MLP –ø–æ–ª–∏—Ç–∏–∫–∏ –∏–∑ SB3
   - –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç—Å—è —á–µ—Ä–µ–∑ `policy_kwargs`

4. **Training loop** (`train_single_agent.py`)
   - –ó–∞–º–µ–Ω–µ–Ω–æ –Ω–∞: `model.learn()` –∏–∑ SB3
   - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —ç–ø–∏–∑–æ–¥–∞–º–∏, —à–∞–≥–∞–º–∏, –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è–º–∏

5. **Action Noise**
   - –ó–∞–º–µ–Ω–µ–Ω–æ –Ω–∞: `OrnsteinUhlenbeckActionNoise` –∏–ª–∏ `NormalActionNoise` –∏–∑ SB3

6. **Checkpointing –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ**
   - –ó–∞–º–µ–Ω–µ–Ω–æ –Ω–∞: –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ callbacks (`CheckpointCallback`, `EvalCallback`)
   - TensorBoard –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–∑ –∫–æ—Ä–æ–±–∫–∏

## –ß—Ç–æ –æ—Å—Ç–∞–ª–æ—Å—å –∫–∞—Å—Ç–æ–º–Ω—ã–º

### üîß –ö–∞—Å—Ç–æ–º–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã (–Ω–µ–æ–±—Ö–æ–¥–∏–º—ã –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞):

1. **–û–∫—Ä—É–∂–µ–Ω–∏–µ** (`env/drone_env.py`)
   - –ö–∞—Å—Ç–æ–º–Ω–∞—è –ª–æ–≥–∏–∫–∞ –¥–≤–∏–∂–µ–Ω–∏—è –¥—Ä–æ–Ω–∞
   - –°–ø–µ—Ü–∏—Ñ–∏—á–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –Ω–∞–≥—Ä–∞–¥—ã
   - –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–µ–ø—è—Ç—Å—Ç–≤–∏–π –∏ —Ü–µ–ª–µ–π

2. **–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä—ã –æ–∫—Ä—É–∂–µ–Ω–∏—è** (`utils/generation.py`)
   - –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–µ–ø—è—Ç—Å—Ç–≤–∏–π
   - –†–∞–∑–Ω—ã–µ —É—Ä–æ–≤–Ω–∏ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏

3. **–§–∏–∑–∏–∫–∞ –¥—Ä–æ–Ω–∞** (`agents/drone.py`)
   - –ú–æ–¥–µ–ª—å –¥–≤–∏–∂–µ–Ω–∏—è —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è–º–∏ —Å–∫–æ—Ä–æ—Å—Ç–∏ –∏ —É–≥–ª–∞

4. **–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è** (`utils/save.py`)
   - –ö–∞—Å—Ç–æ–º–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏ —ç–ø–∏–∑–æ–¥–æ–≤
   - –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—É—Ç–µ–π –¥—Ä–æ–Ω–∞

5. **DB –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ** (`utils/db.py`)
   - –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ DuckDB –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞

6. **Callbacks** (`callbacks/custom_callbacks.py`)
   - –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è DB –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è —Å SB3
   - –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –º–µ–∂–¥—É train/eval —Ä–µ–∂–∏–º–∞–º–∏
   - –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π noise

## –ù–æ–≤–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞

```
model/
‚îú‚îÄ‚îÄ train_sb3.py              # –ù–æ–≤—ã–π training —Å–∫—Ä–∏–ø—Ç —Å SB3
‚îú‚îÄ‚îÄ callbacks/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ custom_callbacks.py  # –ö–∞—Å—Ç–æ–º–Ω—ã–µ callbacks –¥–ª—è SB3
‚îú‚îÄ‚îÄ env/
‚îÇ   ‚îú‚îÄ‚îÄ drone_env.py         # –ö–∞—Å—Ç–æ–º–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
‚îÇ   ‚îî‚îÄ‚îÄ drone_env_wrapper.py # Wrapper –¥–ª—è DB –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îú‚îÄ‚îÄ generation.py        # –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä—ã –æ–∫—Ä—É–∂–µ–Ω–∏—è (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
‚îÇ   ‚îú‚îÄ‚îÄ save.py              # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
‚îÇ   ‚îî‚îÄ‚îÄ db.py                # DB –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
‚îî‚îÄ‚îÄ [—Å—Ç–∞—Ä—ã–µ —Ñ–∞–π–ª—ã –º–æ–∂–Ω–æ —É–¥–∞–ª–∏—Ç—å –ø–æ—Å–ª–µ –ø—Ä–æ–≤–µ—Ä–∫–∏]
```

## –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –æ–±–µ—Ä—Ç–æ–∫

–û–∫—Ä—É–∂–µ–Ω–∏–µ –æ–±–æ—Ä–∞—á–∏–≤–∞–µ—Ç—Å—è –≤ —Å–ª–µ–¥—É—é—â–µ–º –ø–æ—Ä—è–¥–∫–µ:
1. `DroneEnv` - –±–∞–∑–æ–≤–æ–µ –∫–∞—Å—Ç–æ–º–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ
2. `DroneEnvDBWrapper` - –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ –ë–î (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
3. `Monitor` - –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è SB3 (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ)

–≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤—Å—é —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è, –ø—Ä–∏ —ç—Ç–æ–º –∏—Å–ø–æ–ª—å–∑—É—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã SB3.

## –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

### –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π

```bash
poetry install
```

### –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è

```bash
python train_sb3.py
```

### –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –º–µ–∂–¥—É –∞–ª–≥–æ—Ä–∏—Ç–º–∞–º–∏

–í `train_sb3.py` –º–æ–∂–Ω–æ –ª–µ–≥–∫–æ –ø–µ—Ä–µ–∫–ª—é—á–∏—Ç—å—Å—è –º–µ–∂–¥—É –∞–ª–≥–æ—Ä–∏—Ç–º–∞–º–∏:

```python
# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å TD3 (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è - –±–æ–ª–µ–µ —Å—Ç–∞–±–∏–ª—å–Ω—ã–π)
model = TD3("MlpPolicy", train_env, ...)

# –ò–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å DDPG
from stable_baselines3 import DDPG
model = DDPG("MlpPolicy", train_env, ...)
```

## –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥–∞

1. **–ú–µ–Ω—å—à–µ –∫–æ–¥–∞**: ~500 —Å—Ç—Ä–æ–∫ —Å–∞–º–æ–ø–∏—Å–Ω–æ–≥–æ –∫–æ–¥–∞ –∑–∞–º–µ–Ω–µ–Ω–æ –Ω–∞ ~50 —Å—Ç—Ä–æ–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
2. **–ù–∞–¥–µ–∂–Ω–æ—Å—Ç—å**: –ü—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã –∏–∑ SB3 —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è–º–∏
3. **–ì–∏–±–∫–æ—Å—Ç—å**: –õ–µ–≥–∫–æ –ø–µ—Ä–µ–∫–ª—é—á–∞—Ç—å—Å—è –º–µ–∂–¥—É –∞–ª–≥–æ—Ä–∏—Ç–º–∞–º–∏ (DDPG, TD3, SAC)
4. **–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥**: –í—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞ TensorBoard
5. **–°–æ–æ–±—â–µ—Å—Ç–≤–æ**: –ê–∫—Ç–∏–≤–Ω–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è

## –ú–∏–≥—Ä–∞—Ü–∏—è —Å–æ —Å—Ç–∞—Ä–æ–≥–æ –∫–æ–¥–∞

### –°—Ç–∞—Ä—ã–π —Å–ø–æ—Å–æ–±:
```python
agent = DDPGAgent(obs_dim, action_dim, ...)
for episode in range(NUM_EPISODES):
    for step in range(MAX_STEPS):
        action = agent.select_action(obs, noise_std)
        next_obs, reward, done, _ = env.step(action)
        agent.replay_buffer.add(obs, action, reward, next_obs, done)
        agent.update()
```

### –ù–æ–≤—ã–π —Å–ø–æ—Å–æ–±:
```python
model = TD3("MlpPolicy", env, ...)
model.learn(total_timesteps=NUM_EPISODES * MAX_STEPS_PER_EPISODE)
```

## –ß—Ç–æ –º–æ–∂–Ω–æ —É–¥–∞–ª–∏—Ç—å (–ø–æ—Å–ª–µ –ø—Ä–æ–≤–µ—Ä–∫–∏)

–ü–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–æ–≤–æ–≥–æ –∫–æ–¥–∞ –º–æ–∂–Ω–æ —É–¥–∞–ª–∏—Ç—å:

- `agents/ddpg_agent.py`
- `agents/maddpg_agent.py`
- `networks/actor.py`
- `networks/critic.py`
- `utils/per_replay_buffer.py`
- `train_single_agent.py` (—Å—Ç–∞—Ä–∞—è –≤–µ—Ä—Å–∏—è)

## –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏

1. ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω SB3 –∏ —Å–æ–∑–¥–∞–Ω –Ω–æ–≤—ã–π training —Å–∫—Ä–∏–ø—Ç
2. ‚è≥ –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –Ω–æ–≤—ã–π –∫–æ–¥
3. ‚è≥ –£–ª—É—á—à–∏—Ç—å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é DB callback –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
4. ‚è≥ –î–æ–±–∞–≤–∏—Ç—å –ø–æ–¥–¥–µ—Ä–∂–∫—É multi-agent —á–µ—Ä–µ–∑ PettingZoo + SB3
5. ‚è≥ –£–¥–∞–ª–∏—Ç—å —Å—Ç–∞—Ä—ã–π –∫–æ–¥ –ø–æ—Å–ª–µ –ø—Ä–æ–≤–µ—Ä–∫–∏
